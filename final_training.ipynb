{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b3bcd7a6-cd81-4cc2-9551-d84973536277",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from transformers import BertTokenizerFast, BertForTokenClassification, AdamW\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score\n",
    "import torch.nn.functional as F \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6334fe59-f116-46f2-90cd-eb7b518c107f",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 174\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 5\n",
    "MAX_GRAD_NORM = 5\n",
    "MODEL_NAME = 'bert-base-uncased'\n",
    "MODEL_PATH = 'ner_model_from_final1.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f8da028-abcc-4851-8e14-063515161f14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "from torch import cuda\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb968e45-59fc-48b7-9a0b-904bb0ecdbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tag(tag):\n",
    "    # Ensure tags are in the correct format\n",
    "    if tag.count('-') > 1:\n",
    "        prefix, entity = tag.split('-', 1)\n",
    "        tag = f\"{prefix}-{entity.replace('-', '')}\"\n",
    "    return tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dbdb49d-2f74-4994-9241-790cd7935586",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c6b014f-cb52-4d4b-b020-0a477944e5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_names(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        names = [name.strip().lower() for name in file.readlines()]\n",
    "    return names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e560beb-8083-4d0f-8c8d-b59bdb4a0f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(file_path):\n",
    "    sentences, labels = [], []\n",
    "    sentence, label = [], []\n",
    "    with open(file_path, encoding=\"utf-8\") as file:\n",
    "        for line in file:\n",
    "            if line.startswith(\"#\"):\n",
    "                continue\n",
    "            elif line == \"\\n\":\n",
    "                if sentence:\n",
    "                    sentences.append(sentence)\n",
    "                    labels.append(label)\n",
    "                    sentence, label = [], []\n",
    "            else:\n",
    "                parts = line.strip().split(\"\\t\")\n",
    "                sentence.append(parts[1].lower())  # Convert the token to lowercase before appending\n",
    "                label.append(clean_tag(parts[2]))\n",
    "    if sentence:\n",
    "        sentences.append(sentence)\n",
    "        labels.append(label)\n",
    "    return sentences, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "170399a3-f0d6-47b8-8946-a27f7c6c1f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset(Dataset):\n",
    "  def __init__(self, dataframe, tokenizer, max_len):\n",
    "        self.len = len(dataframe)\n",
    "        self.data = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "        # step 1: get the sentence and word labels\n",
    "        sentence = self.data.sentence[index].strip().split()\n",
    "        word_labels = self.data.word_labels[index].split(\",\")\n",
    "\n",
    "        # step 2: use tokenizer to encode sentence (includes padding/truncation up to max length)\n",
    "        # BertTokenizerFast provides a handy \"return_offsets_mapping\" functionality for individual tokens\n",
    "        encoding = self.tokenizer(sentence,\n",
    "                             is_split_into_words=True,\n",
    "                             return_offsets_mapping=True,\n",
    "                             padding='max_length',\n",
    "                             truncation=True,\n",
    "                             max_length=self.max_len)\n",
    "\n",
    "        # step 3: create token labels only for first word pieces of each tokenized word\n",
    "        labels = [labels_to_ids[label] for label in word_labels]\n",
    "        # code based on https://huggingface.co/transformers/custom_datasets.html#tok-ner\n",
    "        # create an empty array of -100 of length max_length\n",
    "        encoded_labels = np.ones(len(encoding[\"offset_mapping\"]), dtype=int) * -100\n",
    "\n",
    "        # set only labels whose first offset position is 0 and the second is not 0\n",
    "        i = 0\n",
    "        for idx, mapping in enumerate(encoding[\"offset_mapping\"]):\n",
    "          if mapping[0] == 0 and mapping[1] != 0:\n",
    "            # overwrite label\n",
    "            encoded_labels[idx] = labels[i]\n",
    "            i += 1\n",
    "\n",
    "        # step 4: turn everything into PyTorch tensors\n",
    "        item = {key: torch.as_tensor(val) for key, val in encoding.items()}\n",
    "        item['labels'] = torch.as_tensor(encoded_labels)\n",
    "\n",
    "        return item\n",
    "\n",
    "  def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06dd2819-7d3f-4b79-9f03-585075d25cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tokens, train_tags = read_data(\"./tagged_sentences_train.iob2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60a7f3c9-9caf-486e-9c4b-6414e7b0ae4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tokens, test_tags = read_data(\"./tagged_sentences_test.iob2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c615e113-fa66-472e-8d85-3aab72ab11e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cogu/.conda/envs/bert-try/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "93af0da7-18d9-434d-b66f-28704162ab46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>word_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>this book is largely concerned with hobbits an...</td>\n",
       "      <td>O,O,O,O,O,O,B-CHAR,O,O,O,O,O,O,O,O,O,O,O,O,O,O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>further information will also be found in the ...</td>\n",
       "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O,B-LOC,O,O,O,O,O,O,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>that story was derived from the earlier chapte...</td>\n",
       "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O,B-CHAR,O,O,O,B-CHA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>many however may wish to know more about this ...</td>\n",
       "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>for such readers a few notes on the more impor...</td>\n",
       "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,B-CHAR,O,O,O,O,O...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  \\\n",
       "0  this book is largely concerned with hobbits an...   \n",
       "1  further information will also be found in the ...   \n",
       "2  that story was derived from the earlier chapte...   \n",
       "3  many however may wish to know more about this ...   \n",
       "4  for such readers a few notes on the more impor...   \n",
       "\n",
       "                                         word_labels  \n",
       "0  O,O,O,O,O,O,B-CHAR,O,O,O,O,O,O,O,O,O,O,O,O,O,O...  \n",
       "1  O,O,O,O,O,O,O,O,O,O,O,O,O,O,B-LOC,O,O,O,O,O,O,...  \n",
       "2  O,O,O,O,O,O,O,O,O,O,O,O,O,O,B-CHAR,O,O,O,B-CHA...  \n",
       "3      O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O  \n",
       "4  O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,B-CHAR,O,O,O,O,O...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {'sentence': [\" \".join(sentence) for sentence in train_tokens],\n",
    "        'word_labels': [\",\".join(tags) for tags in train_tags]}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "06547d33-e5e0-4f2c-a4e0-76dd3696ad3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>word_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>oh smeagol ive got one ive got a fish smeagol ...</td>\n",
       "      <td>O,B-CHAR,O,O,O,O,O,O,O,B-CHAR,I-CHAR,O,O,O,O,O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>because it s my birthday and i wants it</td>\n",
       "      <td>O,O,O,O,O,O,O,O,O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>my precious</td>\n",
       "      <td>O,O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>they cursed us murderer murderer they called us</td>\n",
       "      <td>O,O,O,O,O,O,O,O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>they cursed us and drove us away</td>\n",
       "      <td>O,O,O,O,O,O,O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  \\\n",
       "0  oh smeagol ive got one ive got a fish smeagol ...   \n",
       "1            because it s my birthday and i wants it   \n",
       "2                                        my precious   \n",
       "3    they cursed us murderer murderer they called us   \n",
       "4                   they cursed us and drove us away   \n",
       "\n",
       "                                         word_labels  \n",
       "0  O,B-CHAR,O,O,O,O,O,O,O,B-CHAR,I-CHAR,O,O,O,O,O...  \n",
       "1                                  O,O,O,O,O,O,O,O,O  \n",
       "2                                                O,O  \n",
       "3                                    O,O,O,O,O,O,O,O  \n",
       "4                                      O,O,O,O,O,O,O  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test = {'sentence': [\" \".join(sentence) for sentence in test_tokens],\n",
    "        'word_labels': [\",\".join(tags) for tags in test_tags]}\n",
    "\n",
    "df_test = pd.DataFrame(data_test)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "23aae529-239e-4a03-a844-91b8733c0863",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the word_labels into individual tags and get unique tags\n",
    "all_tags = [tag for tags in df['word_labels'] for tag in tags.split(\",\")]\n",
    "unique_tags = set(all_tags)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f4ab32ee-f6bb-42b2-8821-84b0beee088b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create mappings\n",
    "labels_to_ids = {k: v for v, k in enumerate(unique_tags)}\n",
    "ids_to_labels = {v: k for k, v in labels_to_ids.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eab401c2-2746-4f46-b1be-21fd1048b6ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels_to_ids: {'B-ORG': 0, 'B-CHAR': 1, 'I-CHAR': 2, 'I-LOC': 3, 'B-LOC': 4, 'O': 5}\n",
      "ids_to_labels: {0: 'B-ORG', 1: 'B-CHAR', 2: 'I-CHAR', 3: 'I-LOC', 4: 'B-LOC', 5: 'O'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Display the mappings\n",
    "print(\"labels_to_ids:\", labels_to_ids)\n",
    "print(\"ids_to_labels:\", ids_to_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e34f5b10-6bd5-4abc-9e12-4c6938ca0bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the word_labels into individual tags and get unique tags\n",
    "all_tags_test = [tag for tags in df_test['word_labels'] for tag in tags.split(\",\")]\n",
    "unique_tags_test = set(all_tags_test)\n",
    "\n",
    "# Create mappings\n",
    "labels_to_ids_test = {k: v for v, k in enumerate(unique_tags_test)}\n",
    "ids_to_labels_test = {v: k for k, v in labels_to_ids.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6a14ad0f-933f-4aaa-8805-48b19f838443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels_to_ids: {'B-ORG': 0, 'B-CHAR': 1, 'I-CHAR': 2, 'I-LOC': 3, 'B-LOC': 4, 'O': 5}\n",
      "ids_to_labels: {0: 'B-ORG', 1: 'B-CHAR', 2: 'I-CHAR', 3: 'I-LOC', 4: 'B-LOC', 5: 'O'}\n"
     ]
    }
   ],
   "source": [
    "# Display the mappings\n",
    "print(\"labels_to_ids:\", labels_to_ids_test)\n",
    "print(\"ids_to_labels:\", ids_to_labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "11715252-d6c1-4353-aa04-b8f0c3744d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = dataset(df, tokenizer, MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "30b60396-59bd-4d73-8f63-5056b28acdbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_set = dataset(df_test, tokenizer, MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cc171b87-9949-4820-82af-682fb3614304",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing_set[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "58061efc-ed65-4a9c-80ad-9bc2be396fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for token, label in zip(tokenizer.convert_ids_to_tokens(testing_set[0][\"input_ids\"]), testing_set[0][\"labels\"]):\n",
    "#   print('{0:10}  {1}'.format(token, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1a43bb82-c0ad-4f91-85f5-5471ad3f7c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for token, label in zip(tokenizer.convert_ids_to_tokens(training_set[0][\"input_ids\"]), training_set[0][\"labels\"]):\n",
    "#   print('{0:10}  {1}'.format(token, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "63e3a33b-b7dd-4e20-9e56-390d57550391",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def decode_tokens_and_labels(tokenizer, encoded_input, ids_to_labels):\n",
    "#     # Decode the input_ids to tokens\n",
    "#     tokens = tokenizer.convert_ids_to_tokens(encoded_input['input_ids'].tolist())\n",
    "    \n",
    "#     # Convert label IDs back to label names\n",
    "#     label_ids = encoded_input['labels'].tolist()\n",
    "#     labels = [ids_to_labels[label_id] if label_id != -100 else 'PAD' for label_id in label_ids]\n",
    "    \n",
    "#     # Combine tokens and labels\n",
    "#     decoded = [(token, label) for token, label in zip(tokens, labels)]\n",
    "    \n",
    "#     return decoded\n",
    "\n",
    "# # Example usage:\n",
    "# tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
    "# encoded_input = training_set[0]\n",
    "# decoded_output = decode_tokens_and_labels(tokenizer, encoded_input, ids_to_labels)\n",
    "\n",
    "# for token, label in decoded_output:\n",
    "#     print(f\"{token}: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "da264529-7989-4998-94b6-94eb0349fe23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import torch\n",
    "# from torch.utils.data import Dataset\n",
    "# from transformers import BertTokenizerFast\n",
    "\n",
    "# class CustomDataset(Dataset):\n",
    "#     def __init__(self, dataframe, tokenizer, max_len):\n",
    "#         self.len = len(dataframe)\n",
    "#         self.data = dataframe\n",
    "#         self.tokenizer = tokenizer\n",
    "#         self.max_len = max_len\n",
    "\n",
    "#     def __getitem__(self, index):\n",
    "#         # step 1: get the sentence and word labels\n",
    "#         sentence = self.data.sentence[index].strip().split()\n",
    "#         word_labels = self.data.word_labels[index].split(\",\")\n",
    "\n",
    "#         # step 2: use tokenizer to encode sentence (includes padding/truncation up to max length)\n",
    "#         # BertTokenizerFast provides a handy \"return_offsets_mapping\" functionality for individual tokens\n",
    "#         encoding = self.tokenizer(sentence,\n",
    "#                                   is_split_into_words=True,\n",
    "#                                   return_offsets_mapping=True,\n",
    "#                                   padding='max_length',\n",
    "#                                   truncation=True,\n",
    "#                                   max_length=self.max_len)\n",
    "\n",
    "#         # step 3: create token labels, handling subwords correctly\n",
    "#         labels = [labels_to_ids[label] for label in word_labels]\n",
    "#         encoded_labels = np.ones(len(encoding[\"offset_mapping\"]), dtype=int) * -100\n",
    "\n",
    "#         # set labels for subwords\n",
    "#         i = 0\n",
    "#         for idx, mapping in enumerate(encoding[\"offset_mapping\"]):\n",
    "#             if mapping[0] == 0 and mapping[1] != 0:\n",
    "#                 encoded_labels[idx] = labels[i]\n",
    "#                 i += 1\n",
    "#             elif mapping[0] != 0 and mapping[1] != 0:\n",
    "#                 encoded_labels[idx] = labels[i-1] if word_labels[i-1].startswith(\"B-\") else labels[i-1]\n",
    "\n",
    "#         # step 4: turn everything into PyTorch tensors\n",
    "#         item = {key: torch.as_tensor(val) for key, val in encoding.items()}\n",
    "#         item['labels'] = torch.as_tensor(encoded_labels)\n",
    "\n",
    "#         return item\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return self.len\n",
    "\n",
    "# def read_data(file_path):\n",
    "#     sentences, labels = [], []\n",
    "#     sentence, label = [], []\n",
    "#     with open(file_path, encoding=\"utf-8\") as file:\n",
    "#         for line in file:\n",
    "#             if line.startswith(\"#\"):\n",
    "#                 continue\n",
    "#             elif line == \"\\n\":\n",
    "#                 if sentence:\n",
    "#                     sentences.append(sentence)\n",
    "#                     labels.append(label)\n",
    "#                     sentence, label = [], []\n",
    "#             else:\n",
    "#                 parts = line.strip().split(\"\\t\")\n",
    "#                 sentence.append(parts[1].lower())  # Convert the token to lowercase before appending\n",
    "#                 label.append(clean_tag(parts[2]))\n",
    "#     if sentence:\n",
    "#         sentences.append(sentence)\n",
    "#         labels.append(label)\n",
    "#     return sentences, labels\n",
    "\n",
    "# def clean_tag(tag):\n",
    "#     # Ensure tags are in the correct format\n",
    "#     if tag.count('-') > 1:\n",
    "#         prefix, entity = tag.split('-', 1)\n",
    "#         tag = f\"{prefix}-{entity.replace('-', '')}\"\n",
    "#     return tag\n",
    "\n",
    "# # Example usage\n",
    "# train_tokens, train_tags = read_data(\"./tagged_sentences_train.iob2\")\n",
    "# tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
    "# data = {'sentence': [\" \".join(sentence) for sentence in train_tokens],\n",
    "#         'word_labels': [\",\".join(tags) for tags in train_tags]}\n",
    "\n",
    "# df = pd.DataFrame(data)\n",
    "\n",
    "# # Split the word_labels into individual tags and get unique tags\n",
    "# all_tags = [tag for tags in df['word_labels'] for tag in tags.split(\",\")]\n",
    "# unique_tags = set(all_tags)\n",
    "# print(unique_tags)\n",
    "# print()\n",
    "# # Create mappings\n",
    "# labels_to_ids = {k: v for v, k in enumerate(unique_tags)}\n",
    "# ids_to_labels = {v: k for k, v in labels_to_ids.items()}\n",
    "\n",
    "# MAX_LEN = 128\n",
    "# training_set = CustomDataset(df, tokenizer, MAX_LEN)\n",
    "# decoded_output = decode_tokens_and_labels(tokenizer, training_set[1], ids_to_labels)\n",
    "\n",
    "# for token, label in decoded_output:\n",
    "#     print(f\"{token}: {label}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5707a11d-ea76-4315-8a8a-f1c7e54ca9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_params = {'batch_size': BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "test_params = {'batch_size': BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "training_loader = DataLoader(training_set, **train_params)\n",
    "testing_loader = DataLoader(testing_set, **test_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "55b71ca0-2880-4904-9da2-02aaaeefe7cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels_to_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fd4ae515-764e-4cc4-915d-5e9413d0a1c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cogu/.conda/envs/bert-try/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForTokenClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BertForTokenClassification.from_pretrained('bert-base-uncased', num_labels=len(labels_to_ids))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3b49c63b-9af6-4902-a07c-b2b353260ba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.791759469228055\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "print(-math.log(1/(len(labels_to_ids))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7dfd8bb5-8b25-4b52-94f4-d1f824524241",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.6472, device='cuda:0', grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = training_set[7]\n",
    "input_ids = inputs[\"input_ids\"].unsqueeze(0)\n",
    "attention_mask = inputs[\"attention_mask\"].unsqueeze(0)\n",
    "labels = inputs[\"labels\"].unsqueeze(0)\n",
    "\n",
    "input_ids = input_ids.to(device)\n",
    "attention_mask = attention_mask.to(device)\n",
    "labels = labels.to(device)\n",
    "\n",
    "outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "initial_loss = outputs[0]\n",
    "initial_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "53a67b58-baca-447b-9c9e-cdab687628d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 174, 6])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_logits = outputs[1]\n",
    "tr_logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "42af98d4-aea3-41e3-986c-34b0d4c531ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=3e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7396cc2d-1fa1-4acc-a41f-bf338b0a21d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch: 1\n",
      "Training loss per 100 training steps: 1.7520294189453125\n",
      "Training loss per 100 training steps: 0.12566136439690495\n",
      "Training loss per 100 training steps: 0.0784658856866001\n",
      "Training loss per 100 training steps: 0.05856132630469197\n",
      "Training loss epoch: 0.056738034113173845\n",
      "Training accuracy epoch: 0.9874865240657869\n",
      "Training epoch: 2\n",
      "Training loss per 100 training steps: 0.00999098364263773\n",
      "Training loss per 100 training steps: 0.010535700850668225\n",
      "Training loss per 100 training steps: 0.009953313412733228\n",
      "Training loss per 100 training steps: 0.00957212043443441\n",
      "Training loss epoch: 0.009429574792813153\n",
      "Training accuracy epoch: 0.9973247840704456\n",
      "Training epoch: 3\n",
      "Training loss per 100 training steps: 0.0031392767559736967\n",
      "Training loss per 100 training steps: 0.005265654144822482\n",
      "Training loss per 100 training steps: 0.005301643163834546\n",
      "Training loss per 100 training steps: 0.0050477860340743365\n",
      "Training loss epoch: 0.005081990875739747\n",
      "Training accuracy epoch: 0.998583962076239\n",
      "Training epoch: 4\n",
      "Training loss per 100 training steps: 0.005649829749017954\n",
      "Training loss per 100 training steps: 0.0037497427547350526\n",
      "Training loss per 100 training steps: 0.0034934265599284894\n",
      "Training loss per 100 training steps: 0.0033519714129926245\n",
      "Training loss epoch: 0.0033322809684679065\n",
      "Training accuracy epoch: 0.9990123263288145\n",
      "Training epoch: 5\n",
      "Training loss per 100 training steps: 0.0006332735647447407\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 59\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(EPOCHS):\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining epoch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 59\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[32], line 20\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m     17\u001b[0m tr_logits \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mlogits\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Accumulate the training loss\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m nb_tr_steps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     22\u001b[0m nb_tr_examples \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def train(epoch):\n",
    "    tr_loss, tr_accuracy = 0, 0\n",
    "    nb_tr_examples, nb_tr_steps = 0, 0\n",
    "    tr_preds,tr_labels = [], []\n",
    "\n",
    "    # Put model in training mode\n",
    "    model.train()\n",
    "\n",
    "    for idx, batch in enumerate(training_loader):\n",
    "        ids = batch['input_ids'].to(device, dtype=torch.long)\n",
    "        mask = batch['attention_mask'].to(device, dtype=torch.long)\n",
    "        labels = batch['labels'].to(device, dtype=torch.long)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(input_ids=ids, attention_mask=mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        tr_logits = outputs.logits\n",
    "\n",
    "        # Accumulate the training loss\n",
    "        tr_loss += loss.item()\n",
    "        nb_tr_steps += 1\n",
    "        nb_tr_examples += labels.size(0)\n",
    "\n",
    "        if idx % 100 == 0:\n",
    "            loss_step = tr_loss / nb_tr_steps\n",
    "            print(f\"Training loss per 100 training steps: {loss_step}\")\n",
    "\n",
    "        # Compute training accuracy\n",
    "        flattened_targets = labels.view(-1)  # shape (batch_size * seq_len,)\n",
    "        active_logits = tr_logits.view(-1, model.config.num_labels)  # shape (batch_size * seq_len, num_labels)\n",
    "        flattened_predictions = torch.argmax(active_logits, axis=1)  # shape (batch_size * seq_len,)\n",
    "\n",
    "        # Only compute accuracy at active labels\n",
    "        active_accuracy = labels.view(-1) != -100  # shape (batch_size * seq_len,)\n",
    "        labels = torch.masked_select(flattened_targets, active_accuracy)\n",
    "        predictions = torch.masked_select(flattened_predictions, active_accuracy)\n",
    "\n",
    "        tr_labels.extend(labels.cpu().numpy())\n",
    "        tr_preds.extend(predictions.cpu().numpy())\n",
    "\n",
    "        tmp_tr_accuracy = accuracy_score(labels.cpu().numpy(), predictions.cpu().numpy())\n",
    "        tr_accuracy += tmp_tr_accuracy\n",
    "\n",
    "        # Gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(parameters=model.parameters(), max_norm=MAX_GRAD_NORM)\n",
    "\n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    epoch_loss = tr_loss / nb_tr_steps\n",
    "    tr_accuracy = tr_accuracy / nb_tr_steps\n",
    "    print(f\"Training loss epoch: {epoch_loss}\")\n",
    "    print(f\"Training accuracy epoch: {tr_accuracy}\")\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"Training epoch: {epoch + 1}\")\n",
    "    train(epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f771e1d4-e273-4334-9665-fd088149db96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the path to the saved model directory\n",
    "# directory = \"./model\"\n",
    "\n",
    "# # Load the tokenizer\n",
    "# tokenizer = BertTokenizerFast.from_pretrained(directory)\n",
    "\n",
    "# # Load the model\n",
    "# model = BertForTokenClassification.from_pretrained(directory)\n",
    "# model.to(device)\n",
    "\n",
    "# print('Model and tokenizer loaded successfully')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09dc57e0-6293-46ff-a9ca-5cc07d0fd3b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "146b87fe-fdc5-40a3-af92-04c696262191",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"bert_train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "81b9a007-1229-4f9e-a4f6-acbf7fbc5793",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('tokenizer/tokenizer_config.json',\n",
       " 'tokenizer/special_tokens_map.json',\n",
       " 'tokenizer/vocab.txt',\n",
       " 'tokenizer/added_tokens.json',\n",
       " 'tokenizer/tokenizer.json')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.save_pretrained('tokenizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9f4d7aec-9bb5-4753-a8be-62ca9c3a935a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForTokenClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "config = json.load(open('bert_train/config.json'))\n",
    "config['id2label'] = ids_to_labels\n",
    "config['label2id'] = labels_to_ids\n",
    "json.dump(config, open('bert_train/config.json', 'w'))\n",
    "model = BertForTokenClassification.from_pretrained('bert_train', num_labels=len(labels_to_ids))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "541ed5aa-7cfd-4323-b05b-fc89dd5c1982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation loss: 0.05485333547823959\n",
      "Evaluation accuracy: 0.9900095693779905\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-ORG       0.00      0.00      0.00         2\n",
      "      B-CHAR       0.86      0.86      0.86       820\n",
      "      I-CHAR       0.89      0.78      0.83        85\n",
      "       I-LOC       0.00      0.00      0.00         2\n",
      "       B-LOC       0.94      0.97      0.95       216\n",
      "           O       0.99      1.00      1.00     25000\n",
      "\n",
      "    accuracy                           0.99     26125\n",
      "   macro avg       0.61      0.60      0.61     26125\n",
      "weighted avg       0.99      0.99      0.99     26125\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cogu/.conda/envs/bert-try/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/cogu/.conda/envs/bert-try/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/cogu/.conda/envs/bert-try/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.eval()\n",
    "eval_loss, eval_accuracy = 0, 0\n",
    "nb_eval_steps, nb_eval_examples = 0, 0\n",
    "eval_preds, eval_labels = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for idx, batch in enumerate(testing_loader):\n",
    "        ids = batch['input_ids'].to(device, dtype=torch.long)\n",
    "        mask = batch['attention_mask'].to(device, dtype=torch.long)\n",
    "        labels = batch['labels'].to(device, dtype=torch.long)\n",
    "\n",
    "        outputs = model(input_ids=ids, attention_mask=mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        eval_logits = outputs.logits\n",
    "\n",
    "        eval_loss += loss.item()\n",
    "        nb_eval_steps += 1\n",
    "        nb_eval_examples += labels.size(0)\n",
    "\n",
    "        flattened_targets = labels.view(-1)\n",
    "        active_logits = eval_logits.view(-1, model.config.num_labels)\n",
    "        flattened_predictions = torch.argmax(active_logits, axis=1)\n",
    "\n",
    "        active_accuracy = labels.view(-1) != -100\n",
    "        labels = torch.masked_select(flattened_targets, active_accuracy)\n",
    "        predictions = torch.masked_select(flattened_predictions, active_accuracy)\n",
    "\n",
    "        eval_labels.extend(labels.cpu().numpy())\n",
    "        eval_preds.extend(predictions.cpu().numpy())\n",
    "\n",
    "eval_loss = eval_loss / nb_eval_steps\n",
    "eval_accuracy = accuracy_score(eval_labels, eval_preds)\n",
    "\n",
    "print(f\"Evaluation loss: {eval_loss}\")\n",
    "print(f\"Evaluation accuracy: {eval_accuracy}\")\n",
    "\n",
    "report = classification_report(eval_labels, eval_preds, target_names=list(labels_to_ids.keys()))\n",
    "print(\"Classification Report:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a9ac5ed1-0b4f-4b8e-b55f-bf5104d18f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid(model, testing_loader):\n",
    "    # put model in evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_examples, nb_eval_steps = 0, 0\n",
    "    eval_preds, eval_labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, batch in enumerate(testing_loader):\n",
    "\n",
    "            ids = batch['input_ids'].to(device, dtype=torch.long)\n",
    "            mask = batch['attention_mask'].to(device, dtype=torch.long)\n",
    "            labels = batch['labels'].to(device, dtype=torch.long)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(input_ids=ids, attention_mask=mask, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            eval_logits = outputs.logits\n",
    "\n",
    "            eval_loss += loss.item()\n",
    "\n",
    "            nb_eval_steps += 1\n",
    "            nb_eval_examples += labels.size(0)\n",
    "\n",
    "            if idx % 100 == 0:\n",
    "                loss_step = eval_loss / nb_eval_steps\n",
    "                print(f\"Validation loss per 100 evaluation steps: {loss_step}\")\n",
    "\n",
    "            # Compute evaluation accuracy\n",
    "            flattened_targets = labels.view(-1)  # shape (batch_size * seq_len,)\n",
    "            active_logits = eval_logits.view(-1, model.config.num_labels)  # shape (batch_size * seq_len, num_labels)\n",
    "            flattened_predictions = torch.argmax(active_logits, axis=1)  # shape (batch_size * seq_len,)\n",
    "\n",
    "            # Only compute accuracy at active labels\n",
    "            active_accuracy = labels.view(-1) != -100  # shape (batch_size * seq_len,)\n",
    "            labels = torch.masked_select(flattened_targets, active_accuracy)\n",
    "            predictions = torch.masked_select(flattened_predictions, active_accuracy)\n",
    "\n",
    "            eval_labels.extend(labels.cpu().numpy())\n",
    "            eval_preds.extend(predictions.cpu().numpy())\n",
    "\n",
    "            tmp_eval_accuracy = accuracy_score(labels.cpu().numpy(), predictions.cpu().numpy())\n",
    "            eval_accuracy += tmp_eval_accuracy\n",
    "\n",
    "    labels = [ids_to_labels[id] for id in eval_labels]\n",
    "    predictions = [ids_to_labels[id] for id in eval_preds]\n",
    "\n",
    "    eval_loss = eval_loss / nb_eval_steps\n",
    "    eval_accuracy = eval_accuracy / nb_eval_steps\n",
    "    print(f\"Validation Loss: {eval_loss}\")\n",
    "    print(f\"Validation Accuracy: {eval_accuracy}\")\n",
    "\n",
    "    return labels, predictions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "27e9ff79-30de-4e22-ae67-5f1780f41872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation function\n",
    "def evaluate():\n",
    "    model.eval()\n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_steps, nb_eval_examples = 0, 0\n",
    "    eval_preds, eval_labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, batch in enumerate(testing_loader):\n",
    "            ids = batch['input_ids'].to(device, dtype=torch.long)\n",
    "            mask = batch['attention_mask'].to(device, dtype=torch.long)\n",
    "            labels = batch['labels'].to(device, dtype=torch.long)\n",
    "\n",
    "            outputs = model(input_ids=ids, attention_mask=mask, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            eval_logits = outputs.logits\n",
    "\n",
    "            eval_loss += loss.item()\n",
    "            nb_eval_steps += 1\n",
    "            nb_eval_examples += labels.size(0)\n",
    "\n",
    "            flattened_targets = labels.view(-1)\n",
    "            active_logits = eval_logits.view(-1, model.config.num_labels)\n",
    "            flattened_predictions = torch.argmax(active_logits, axis=1)\n",
    "\n",
    "            active_accuracy = labels.view(-1) != -100\n",
    "            labels = torch.masked_select(flattened_targets, active_accuracy)\n",
    "            predictions = torch.masked_select(flattened_predictions, active_accuracy)\n",
    "\n",
    "            eval_labels.extend(labels.cpu().numpy())\n",
    "            eval_preds.extend(predictions.cpu().numpy())\n",
    "\n",
    "    eval_loss = eval_loss / nb_eval_steps\n",
    "    eval_accuracy = accuracy_score(eval_labels, eval_preds)\n",
    "\n",
    "    print(f\"Evaluation loss: {eval_loss}\")\n",
    "    print(f\"Evaluation accuracy: {eval_accuracy}\")\n",
    "\n",
    "    # Get sorted list of label IDs\n",
    "    sorted_labels = sorted(labels_to_ids, key=labels_to_ids.get)\n",
    "\n",
    "    report = classification_report(eval_labels, eval_preds, labels=[labels_to_ids[label] for label in sorted_labels], target_names=sorted_labels)\n",
    "    print(\"Classification Report:\")\n",
    "    print(report)\n",
    "# evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d5bc03f6-f975-4d74-81b8-133674add877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per 100 evaluation steps: 0.05313334986567497\n",
      "Validation Loss: 0.05507717819677459\n",
      "Validation Accuracy: 0.9898758699840837\n"
     ]
    }
   ],
   "source": [
    "labels, predictions = valid(model, testing_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "911276ff-0435-42d7-a9a6-bf9a4a959308",
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid(model, testing_loader):\n",
    "    # put model in evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_examples, nb_eval_steps = 0, 0\n",
    "    eval_preds, eval_labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, batch in enumerate(testing_loader):\n",
    "            ids = batch['input_ids'].to(device, dtype=torch.long)\n",
    "            mask = batch['attention_mask'].to(device, dtype=torch.long)\n",
    "            labels = batch['labels'].to(device, dtype=torch.long)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(input_ids=ids, attention_mask=mask, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            eval_logits = outputs.logits\n",
    "\n",
    "            eval_loss += loss.item()\n",
    "            nb_eval_steps += 1\n",
    "            nb_eval_examples += labels.size(0)\n",
    "\n",
    "            if idx % 100 == 0:\n",
    "                loss_step = eval_loss / nb_eval_steps\n",
    "                print(f\"Validation loss per 100 evaluation steps: {loss_step}\")\n",
    "\n",
    "            # Compute evaluation accuracy\n",
    "            active_logits = eval_logits.view(-1, model.config.num_labels)  # shape (batch_size * seq_len, num_labels)\n",
    "            flattened_predictions = torch.argmax(active_logits, axis=1)  # shape (batch_size * seq_len,)\n",
    "\n",
    "            for i in range(labels.size(0)):\n",
    "                label = labels[i]\n",
    "                pred = flattened_predictions.view(labels.size(0), labels.size(1))[i]\n",
    "\n",
    "                active_accuracy = label != -100  # shape (seq_len,)\n",
    "                label = torch.masked_select(label, active_accuracy)\n",
    "                pred = torch.masked_select(pred, active_accuracy)\n",
    "\n",
    "                eval_labels.append([ids_to_labels[id.item()] for id in label])\n",
    "                eval_preds.append([ids_to_labels[id.item()] for id in pred])\n",
    "\n",
    "                tmp_eval_accuracy = accuracy_score(label.cpu().numpy(), pred.cpu().numpy())\n",
    "                eval_accuracy += tmp_eval_accuracy\n",
    "\n",
    "    eval_loss = eval_loss / nb_eval_steps\n",
    "    eval_accuracy = eval_accuracy / nb_eval_steps\n",
    "    print(f\"Validation Loss: {eval_loss}\")\n",
    "    print(f\"Validation Accuracy: {eval_accuracy}\")\n",
    "\n",
    "    return eval_labels, eval_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2d6f4b6f-d1e0-41d6-b3f2-a525c736f5f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per 100 evaluation steps: 0.037515584379434586\n",
      "Validation Loss: 0.05498418704503112\n",
      "Validation Accuracy: 62.92922030032321\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "labels, predictions = valid(model, testing_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0dafbb-c18c-413f-bb8c-e281394b18f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca3bb4d-9396-4bf0-899c-65a31c376297",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7daa1b43-dcd2-476f-9dfe-853fdd35f8df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        CHAR       0.84      0.84      0.84       820\n",
      "         LOC       0.93      0.96      0.95       216\n",
      "         ORG       0.00      0.00      0.00         2\n",
      "\n",
      "   micro avg       0.86      0.87      0.86      1038\n",
      "   macro avg       0.59      0.60      0.60      1038\n",
      "weighted avg       0.86      0.87      0.86      1038\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cogu/.conda/envs/bert-try/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from seqeval.metrics import classification_report\n",
    "\n",
    "print(classification_report(labels, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f009d8-3f61-4c47-90ca-7b72d4a35666",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f2bbc689-3119-43ae-8d26-907efd73575f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizerFast.from_pretrained(\"tokenizer\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "afafc9cb-84bc-4913-93a7-40aa245edab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Oooohhh', 'Frodo', 'Aaaahh', 'Gimli', 'My', 'precious', 'Wake', 'up', 'Wake', 'up', 'Wake', 'up', 'sleepies', 'We', 'must', 'go', 'yes', 'we', 'must', 'go', 'at', 'once']\n",
      "['O', 'B-CHAR', 'O', 'B-CHAR', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "sentence = \"Oooohhh Frodo Aaaahh Gimli My precious Wake up Wake up Wake up sleepies We must go yes we must go at once\"\n",
    "words = sentence.split()\n",
    "inputs = tokenizer(words,\n",
    "             is_split_into_words=True,\n",
    "             return_offsets_mapping=True,\n",
    "             padding='max_length',\n",
    "             truncation=True,\n",
    "             max_length=MAX_LEN,\n",
    "             return_tensors=\"pt\")\n",
    "\n",
    "\n",
    "# move to gpu\n",
    "ids = inputs[\"input_ids\"].to(device)\n",
    "mask = inputs[\"attention_mask\"].to(device)\n",
    "# forward pass\n",
    "outputs = model(ids, attention_mask=mask)\n",
    "logits = outputs[0]\n",
    "\n",
    "active_logits = logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
    "flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size*seq_len,) - predictions at the token level\n",
    "\n",
    "tokens = tokenizer.convert_ids_to_tokens(ids.squeeze().tolist())\n",
    "token_predictions = [ids_to_labels[i] for i in flattened_predictions.cpu().numpy()]\n",
    "wp_preds = list(zip(tokens, token_predictions)) # list of tuples. Each tuple = (wordpiece, prediction)\n",
    "\n",
    "prediction = []\n",
    "for token_pred, mapping in zip(wp_preds, inputs[\"offset_mapping\"].squeeze().tolist()):\n",
    "  #only predictions on first word pieces are important\n",
    "  if mapping[0] == 0 and mapping[1] != 0:\n",
    "    prediction.append(token_pred[1])\n",
    "  else:\n",
    "    continue\n",
    "\n",
    "print(sentence.split())\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f25cd6a1-a1a2-463f-a8d8-e56b350b588c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Oh', 'Smeagol', 'Ive', 'got', 'one', 'Ive', 'got', 'a', 'fish', 'Smeagol', 'Smeagol', 'Pull', 'it', 'in', 'Go', 'on', 'go', 'on', 'go', 'on', 'pull', 'it', 'in', 'Arrghh', 'Deagol', 'Deagol', 'Deagol', 'Give', 'us', 'that', 'Deagol', 'my', 'love', 'Why']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Ensure MAX_LEN is defined\n",
    "MAX_LEN = 128\n",
    "\n",
    "sentence = \"Oh Smeagol Ive got one Ive got a fish Smeagol Smeagol Pull it in Go on go on go on pull it in Arrghh Deagol Deagol Deagol Give us that Deagol my love Why\"\n",
    "words = sentence.split()\n",
    "inputs = tokenizer(words,\n",
    "             is_split_into_words=True,\n",
    "             return_offsets_mapping=True,\n",
    "             padding='max_length',\n",
    "             truncation=True,\n",
    "             max_length=MAX_LEN,\n",
    "             return_tensors=\"pt\")\n",
    "\n",
    "# move to gpu\n",
    "ids = inputs[\"input_ids\"].to(device)\n",
    "mask = inputs[\"attention_mask\"].to(device)\n",
    "# forward pass\n",
    "outputs = model(ids, attention_mask=mask)\n",
    "logits = outputs.logits\n",
    "\n",
    "active_logits = logits.view(-1, model.config.num_labels) # shape (batch_size * seq_len, num_labels)\n",
    "flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size*seq_len,) - predictions at the token level\n",
    "\n",
    "tokens = tokenizer.convert_ids_to_tokens(ids.squeeze().tolist())\n",
    "token_predictions = [ids_to_labels[i] for i in flattened_predictions.cpu().numpy()]\n",
    "wp_preds = list(zip(tokens, token_predictions)) # list of tuples. Each tuple = (wordpiece, prediction)\n",
    "\n",
    "prediction = []\n",
    "for token_pred, mapping in zip(wp_preds, inputs[\"offset_mapping\"].squeeze().tolist()):\n",
    "  # only predictions on first word pieces are important\n",
    "  if mapping[0] == 0 and mapping[1] != 0:\n",
    "    prediction.append(token_pred[1])\n",
    "  else:\n",
    "    continue\n",
    "\n",
    "print(words)\n",
    "print(prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c7ad79be-7413-4320-9469-50a125a1e707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/cogu/.conda/envs/bert-try/lib/python3.10/site-packages/transformers/utils/import_utils.py\", line 1510, in _get_module\n",
      "    def __dir__(self):\n",
      "  File \"/home/cogu/.conda/envs/bert-try/lib/python3.10/importlib/__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 1050, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 1006, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 688, in _load_unlocked\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"/home/cogu/.conda/envs/bert-try/lib/python3.10/site-packages/transformers/pipelines/__init__.py\", line 47, in <module>\n",
      "    from .audio_classification import AudioClassificationPipeline\n",
      "  File \"/home/cogu/.conda/envs/bert-try/lib/python3.10/site-packages/transformers/pipelines/audio_classification.py\", line 21, in <module>\n",
      "    from .base import Pipeline, build_pipeline_init_args\n",
      "  File \"/home/cogu/.conda/envs/bert-try/lib/python3.10/site-packages/transformers/pipelines/base.py\", line 34, in <module>\n",
      "    from ..modelcard import ModelCard\n",
      "  File \"/home/cogu/.conda/envs/bert-try/lib/python3.10/site-packages/transformers/modelcard.py\", line 48, in <module>\n",
      "    from .training_args import ParallelMode\n",
      "  File \"/home/cogu/.conda/envs/bert-try/lib/python3.10/site-packages/transformers/training_args.py\", line 70, in <module>\n",
      "    from .pytorch_utils import is_torch_greater_or_equal_than_2_0, is_torch_greater_or_equal_than_2_3\n",
      "ImportError: cannot import name 'is_torch_greater_or_equal_than_2_3' from 'transformers.pytorch_utils' (/home/cogu/.conda/envs/bert-try/lib/python3.10/site-packages/transformers/pytorch_utils.py)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/cogu/.conda/envs/bert-try/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_8876/4287807559.py\", line 1, in <module>\n",
      "    from transformers import pipeline\n",
      "  File \"<frozen importlib._bootstrap>\", line 1075, in _handle_fromlist\n",
      "  File \"/home/cogu/.conda/envs/bert-try/lib/python3.10/site-packages/transformers/utils/import_utils.py\", line 1500, in __getattr__\n",
      "    # Needed for autocompletion in an IDE\n",
      "  File \"/home/cogu/.conda/envs/bert-try/lib/python3.10/site-packages/transformers/utils/import_utils.py\", line 1512, in _get_module\n",
      "    # The elements of self.__all__ that are submodules may or may not be in the dir already, depending on whether\n",
      "RuntimeError: Failed to import transformers.pipelines because of the following error (look up to see its traceback):\n",
      "cannot import name 'is_torch_greater_or_equal_than_2_3' from 'transformers.pytorch_utils' (/home/cogu/.conda/envs/bert-try/lib/python3.10/site-packages/transformers/pytorch_utils.py)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/cogu/.conda/envs/bert-try/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 2144, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"/home/cogu/.conda/envs/bert-try/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1435, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"/home/cogu/.conda/envs/bert-try/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1326, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"/home/cogu/.conda/envs/bert-try/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1192, in structured_traceback\n",
      "    formatted_exceptions += self.format_exception_as_a_whole(etype, evalue, etb, lines_of_context,\n",
      "  File \"/home/cogu/.conda/envs/bert-try/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1088, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(record))\n",
      "  File \"/home/cogu/.conda/envs/bert-try/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 970, in format_record\n",
      "    frame_info.lines, Colors, self.has_colors, lvals\n",
      "  File \"/home/cogu/.conda/envs/bert-try/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 792, in lines\n",
      "    return self._sd.lines\n",
      "  File \"/home/cogu/.conda/envs/bert-try/lib/python3.10/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/home/cogu/.conda/envs/bert-try/lib/python3.10/site-packages/stack_data/core.py\", line 698, in lines\n",
      "    pieces = self.included_pieces\n",
      "  File \"/home/cogu/.conda/envs/bert-try/lib/python3.10/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/home/cogu/.conda/envs/bert-try/lib/python3.10/site-packages/stack_data/core.py\", line 649, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "  File \"/home/cogu/.conda/envs/bert-try/lib/python3.10/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/home/cogu/.conda/envs/bert-try/lib/python3.10/site-packages/stack_data/core.py\", line 628, in executing_piece\n",
      "    return only(\n",
      "  File \"/home/cogu/.conda/envs/bert-try/lib/python3.10/site-packages/executing/executing.py\", line 164, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a17c8a9-8f5a-4e86-9131-08826edf3792",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50db4385-a321-4c8a-a4bb-e54c05c406e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e276f48b-6826-48a2-a1f9-b846d0e83451",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3b6e22-1693-4611-8292-9f01467194da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483773e5-fd4f-4fb8-af6d-aedc4b00f92e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "eeb2bfe3-93b1-4339-8f07-f7505650ad53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "\n",
    "# directory = \"./model\"\n",
    "\n",
    "# if not os.path.exists(directory):\n",
    "#     os.makedirs(directory)\n",
    "\n",
    "# # save vocabulary of the tokenizer\n",
    "# tokenizer.save_vocabulary(directory)\n",
    "# # save the model weights and its configuration file\n",
    "# model.save_pretrained(directory)\n",
    "# print('All files saved')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "480bf7b2-43d2-45bf-b1ba-723242c16872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels_to_ids: {'B-ORG': 0, 'B-CHAR': 1, 'I-CHAR': 2, 'I-LOC': 3, 'B-LOC': 4, 'O': 5}\n",
      "ids_to_labels: {0: 'B-ORG', 1: 'B-CHAR', 2: 'I-CHAR', 3: 'I-LOC', 4: 'B-LOC', 5: 'O'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Display the mappings\n",
    "print(\"labels_to_ids:\", labels_to_ids)\n",
    "print(\"ids_to_labels:\", ids_to_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6029fd27-492d-44d6-81cc-108f0505f674",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForTokenClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "config = json.load(open('bert_train/config.json'))\n",
    "config['id2label'] = ids_to_labels\n",
    "config['label2id'] = labels_to_ids\n",
    "json.dump(config, open('bert_train/config.json', 'w'))\n",
    "model = BertForTokenClassification.from_pretrained('bert_train', num_labels=len(labels_to_ids))\n",
    "model.to(device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (bert-try)",
   "language": "python",
   "name": "bert-try"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
