{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "1tfgKEw_yvjI"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cogu/.conda/envs/bert-try/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from transformers import BertTokenizerFast, BertForTokenClassification, AdamW\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score\n",
    "import torch.nn.functional as F  # Add this import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "k4jsQjQ3y6md"
   },
   "outputs": [],
   "source": [
    "MAX_LEN = 174\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 1\n",
    "MODEL_NAME = 'bert-base-uncased'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tag(tag):\n",
    "    # Ensure tags are in the correct format\n",
    "    if tag.count('-') > 1:\n",
    "        prefix, entity = tag.split('-', 1)\n",
    "        tag = f\"{prefix}-{entity.replace('-', '')}\"\n",
    "    return tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "-TUJuFDDy8ZL"
   },
   "outputs": [],
   "source": [
    "def read_data(file_path):\n",
    "    sentences, labels = [], []\n",
    "    sentence, label = [], []\n",
    "    with open(file_path, encoding=\"utf-8\") as file:\n",
    "        for line in file:\n",
    "            if line.startswith(\"#\"):\n",
    "                continue\n",
    "            elif line == \"\\n\":\n",
    "                if sentence:\n",
    "                    sentences.append(sentence)\n",
    "                    labels.append(label)\n",
    "                    sentence, label = [], []\n",
    "            else:\n",
    "                parts = line.strip().split(\"\\t\")\n",
    "                sentence.append(parts[1].lower())  # Convert the token to lowercase before appending\n",
    "                label.append(clean_tag(parts[2]))\n",
    "    if sentence:\n",
    "        sentences.append(sentence)\n",
    "        labels.append(label)\n",
    "    return sentences, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "KsDtZFp3y-A3"
   },
   "outputs": [],
   "source": [
    "def read_names(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        names = [name.strip().lower() for name in file.readlines()]\n",
    "    return names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "1vLOalEGy_JO"
   },
   "outputs": [],
   "source": [
    "character_names = read_names('./scraping_res/character_names.txt')\n",
    "location_names = read_names('./scraping_res/location_names.txt')\n",
    "organization_names = read_names('./scraping_res/organization_names.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "yYspNUGczBqR"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cogu/.conda/envs/bert-try/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "all_names = character_names + location_names + organization_names\n",
    "\n",
    "tokenizer = BertTokenizerFast.from_pretrained(MODEL_NAME)\n",
    "num_added_toks = tokenizer.add_tokens(all_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "A8S2iqb6zDXq"
   },
   "outputs": [],
   "source": [
    "train_tokens, train_tags = read_data(\"./tagged_sentences_train.iob2\")\n",
    "tag_values = list(set(tag for doc in train_tags for tag in doc))\n",
    "tag_values.append(\"PAD\")\n",
    "tag2idx = {tag: idx for idx, tag in enumerate(tag_values)}\n",
    "idx2tag = dict([(value, key) for key, value in tag2idx.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "print(len(tag2idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'B-CHAR', 'B-LOC', 'B-ORG', 'I-CHAR', 'I-LOC', 'O'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(set(tag for doc in train_tags for tag in doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tag_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tokens, test_tags = read_data(\"./tagged_sentences_test.iob2\")\n",
    "\n",
    "# Combine train and test tags to create a comprehensive tag set\n",
    "all_tags = set(tag for doc in train_tags for tag in doc).union(set(tag for doc in test_tags for tag in doc))\n",
    "all_tags.add(\"PAD\")  # Add the PAD tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tags: {'I-CHAR', 'B-CHAR', 'I-LOC', 'O', 'B-LOC', 'PAD', 'B-ORG'}\n"
     ]
    }
   ],
   "source": [
    "print(f\"All tags: {all_tags}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "Wow4uE_YzEqq"
   },
   "outputs": [],
   "source": [
    "class NERDataset(Dataset):\n",
    "    def __init__(self, sentences, tags, tokenizer, max_len, tag2idx):\n",
    "        self.sentences = sentences\n",
    "        self.tags = tags\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        self.tag2idx = tag2idx\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sentences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sentence = self.sentences[idx]\n",
    "        word_labels = self.tags[idx]\n",
    "        encoding = self.tokenizer(sentence, is_split_into_words=True, return_offsets_mapping=True, padding='max_length', truncation=True, max_length=self.max_len, return_tensors='pt')\n",
    "        labels = [self.tag2idx['O']] * self.max_len  # Initialize labels with \"O\"\n",
    "        offsets = encoding['offset_mapping'].squeeze().tolist()  # Get the offsets\n",
    "        encoding.pop('offset_mapping')  # Remove offsets, not needed for model input\n",
    "\n",
    "        idx = 0\n",
    "        for i, (start, end) in enumerate(offsets):\n",
    "            if start == end:  # Special tokens\n",
    "                labels[i] = self.tag2idx['O']\n",
    "            elif start == 0:  # Start of a new word\n",
    "                if idx < len(word_labels):\n",
    "                    labels[i] = self.tag2idx[word_labels[idx]]\n",
    "                else:\n",
    "                    labels[i] = self.tag2idx['O']\n",
    "                idx += 1\n",
    "            else:  # Subtoken of a word\n",
    "                labels[i] = -100  # PyTorch's convention to ignore these tokens in loss computation\n",
    "\n",
    "        item = {key: val.squeeze() for key, val in encoding.items()}  # Remove batch dimension\n",
    "        item['labels'] = torch.tensor(labels)\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "OqOe-qWHzGva"
   },
   "outputs": [],
   "source": [
    "train_data = NERDataset(train_tokens, train_tags, tokenizer, MAX_LEN, tag2idx)\n",
    "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "0mpkIUg9zJn8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = BertForTokenClassification.from_pretrained(MODEL_NAME, num_labels=len(tag_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "EIHx-90MzLIX"
   },
   "outputs": [],
   "source": [
    "if num_added_toks > 0:\n",
    "    model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "4zLT39sgzMmL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cogu/.conda/envs/bert-try/lib/python3.10/site-packages/transformers/optimization.py:521: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Using device: {device}')\n",
    "model.to(device)\n",
    "optimizer = AdamW(model.parameters(), lr=3e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "VmCpnyIPzN5z"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Using device: cuda\n",
      "Epoch 1, Step 0, Loss: 1.6785365343093872\n",
      "Epoch 1, Step 10, Loss: 0.045099589973688126\n",
      "Epoch 1, Step 20, Loss: 0.015861421823501587\n",
      "Epoch 1, Step 30, Loss: 0.022854037582874298\n",
      "Epoch 1, Step 40, Loss: 0.029340513050556183\n",
      "Epoch 1, Step 50, Loss: 0.01307598315179348\n",
      "Epoch 1, Step 60, Loss: 0.032763056457042694\n",
      "Epoch 1, Step 70, Loss: 0.019419947639107704\n",
      "Epoch 1, Step 80, Loss: 0.013492172583937645\n",
      "Epoch 1, Step 90, Loss: 0.02313671074807644\n",
      "Epoch 1, Step 100, Loss: 0.022113250568509102\n",
      "Epoch 1, Step 110, Loss: 0.01595035195350647\n",
      "Epoch 1, Step 120, Loss: 0.011320076882839203\n",
      "Epoch 1, Step 130, Loss: 0.011424909345805645\n",
      "Epoch 1, Step 140, Loss: 0.009597595781087875\n",
      "Epoch 1, Step 150, Loss: 0.005002311430871487\n",
      "Epoch 1, Step 160, Loss: 0.0041248612105846405\n",
      "Epoch 1, Step 170, Loss: 0.009335093200206757\n",
      "Epoch 1, Step 180, Loss: 0.006383749656379223\n",
      "Epoch 1, Step 190, Loss: 0.007022277917712927\n",
      "Epoch 1, Step 200, Loss: 0.004724388942122459\n",
      "Epoch 1, Step 210, Loss: 0.0073069678619503975\n",
      "Epoch 1, Step 220, Loss: 0.005426591262221336\n",
      "Epoch 1, Step 230, Loss: 0.005231909453868866\n",
      "Epoch 1, Step 240, Loss: 0.006270269863307476\n",
      "Epoch 1, Step 250, Loss: 0.002249099314212799\n",
      "Epoch 1, Step 260, Loss: 0.006492003798484802\n",
      "Epoch 1, Step 270, Loss: 0.004103329963982105\n",
      "Epoch 1, Step 280, Loss: 0.0061763799749314785\n",
      "Epoch 1, Step 290, Loss: 0.004696184769272804\n",
      "Epoch 1, Step 300, Loss: 0.005074842367321253\n",
      "Epoch 1, Step 310, Loss: 0.001903606578707695\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "print(f'Using device: {device}')\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f'Using device: {device}')\n",
    "    for step, batch in enumerate(train_loader):\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs[0]\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if step % 10 == 0:\n",
    "            print(f\"Epoch {epoch + 1}, Step {step}, Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load the test data\n",
    "test_tokens, test_tags = read_data(\"./tagged_sentences_test.iob2\")\n",
    "\n",
    "# Step 2: Create a DataLoader for the test data\n",
    "test_data = NERDataset(test_tokens, test_tags, tokenizer, MAX_LEN, tag2idx)\n",
    "test_loader = DataLoader(test_data, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss: 0.005300000141788688\n",
      "F1 Score (excluding PAD and O): 0.5369410231345716\n",
      "Accuracy (excluding PAD and O): 0.5582222222222222\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      I-CHAR       0.00      0.00      0.00        85\n",
      "      B-CHAR       0.71      0.77      0.74       820\n",
      "       I-LOC       0.00      0.00      0.00         2\n",
      "       B-LOC       0.00      0.00      0.00       216\n",
      "       B-ORG       0.00      0.00      0.00         2\n",
      "\n",
      "   micro avg       0.71      0.56      0.62      1125\n",
      "   macro avg       0.14      0.15      0.15      1125\n",
      "weighted avg       0.52      0.56      0.54      1125\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cogu/.conda/envs/bert-try/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/cogu/.conda/envs/bert-try/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/cogu/.conda/envs/bert-try/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score, classification_report\n",
    "\n",
    "# Define evaluation function\n",
    "def evaluate(model, dataloader, device, tag2idx, idx2tag):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            outputs = model(**batch)\n",
    "            loss = outputs.loss\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            logits = outputs.logits\n",
    "            predictions = torch.argmax(logits, dim=2)\n",
    "\n",
    "            # Collect the predictions and true labels for calculating F1 score and accuracy\n",
    "            all_preds.extend(predictions.cpu().numpy().tolist())\n",
    "            all_labels.extend(batch['labels'].cpu().numpy().tolist())\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "\n",
    "    # Flatten the lists to calculate metrics\n",
    "    all_preds_flat = [p for preds in all_preds for p in preds]\n",
    "    all_labels_flat = [l for labels in all_labels for l in labels]\n",
    "\n",
    "    # Remove padding tokens, the label 0 (O), and -100 for accuracy and F1 calculation\n",
    "    true_preds = [pred for pred, label in zip(all_preds_flat, all_labels_flat) if label != tag2idx['PAD'] and label != tag2idx['O'] and label != -100]\n",
    "    true_labels = [label for label in all_labels_flat if label != tag2idx['PAD'] and label != tag2idx['O'] and label != -100]\n",
    "\n",
    "    # Map indices back to tags\n",
    "    true_preds_tags = [idx2tag[pred] for pred in true_preds]\n",
    "    true_labels_tags = [idx2tag[label] for label in true_labels]\n",
    "\n",
    "    # Get the list of unique tags in the dataset (excluding PAD and O)\n",
    "    unique_tags = [tag for tag in tag2idx if tag != 'PAD' and tag != 'O']\n",
    "\n",
    "    f1 = f1_score(true_labels_tags, true_preds_tags, average='weighted')\n",
    "    accuracy = accuracy_score(true_labels_tags, true_preds_tags)\n",
    "\n",
    "    print(f'Average Loss: {avg_loss}')\n",
    "    print(f'F1 Score (excluding PAD and O): {f1}')\n",
    "    print(f'Accuracy (excluding PAD and O): {accuracy}')\n",
    "    print(classification_report(true_labels_tags, true_preds_tags, labels=unique_tags, target_names=unique_tags))\n",
    "\n",
    "    return avg_loss, f1, accuracy, true_labels_tags, true_preds_tags\n",
    "\n",
    "# Example usage\n",
    "avg_loss, f1, accuracy, true_labels_tags, true_preds_tags = evaluate(model, test_loader, device, tag2idx, idx2tag)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def evaluate(model, dataloader, device, tag2idx, idx2tag):\n",
    "#     model.eval()\n",
    "#     total_loss = 0\n",
    "#     all_preds = []\n",
    "#     all_labels = []\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         for batch in dataloader:\n",
    "#             batch = {k: v.to(device) for k, v in batch.items()}\n",
    "#             outputs = model(**batch)\n",
    "#             loss = outputs.loss\n",
    "#             total_loss += loss.item()\n",
    "\n",
    "#             logits = outputs.logits\n",
    "#             predictions = torch.argmax(logits, dim=2)\n",
    "\n",
    "#             # Collect the predictions and true labels for calculating F1 score and accuracy\n",
    "#             all_preds.extend(predictions.cpu().numpy().tolist())\n",
    "#             all_labels.extend(batch['labels'].cpu().numpy().tolist())\n",
    "\n",
    "#     avg_loss = total_loss / len(dataloader)\n",
    "\n",
    "#     # Flatten the lists to calculate metrics\n",
    "#     all_preds_flat = [p for preds in all_preds for p in preds]\n",
    "#     all_labels_flat = [l for labels in all_labels for l in labels]\n",
    "\n",
    "#     # Remove padding tokens, the label 0 (O), and -100 for accuracy and F1 calculation\n",
    "#     true_preds = [pred for pred, label in zip(all_preds_flat, all_labels_flat) if label != tag2idx['PAD'] and label != tag2idx['O'] and label != -100]\n",
    "#     true_labels = [label for label in all_labels_flat if label != tag2idx['PAD'] and label != tag2idx['O'] and label != -100]\n",
    "\n",
    "#     # Map indices back to tags\n",
    "#     true_preds_tags = [idx2tag[pred] for pred in true_preds]\n",
    "#     true_labels_tags = [idx2tag[label] for label in true_labels]\n",
    "\n",
    "#     # Get the list of unique tags in the dataset (excluding PAD and O)\n",
    "#     unique_tags = [tag for tag in tag2idx if tag != 'PAD' and tag != 'O']\n",
    "\n",
    "#     f1 = f1_score(true_labels_tags, true_preds_tags, average='weighted')\n",
    "#     accuracy = accuracy_score(true_labels_tags, true_preds_tags)\n",
    "\n",
    "#     return avg_loss, f1, accuracy, true_labels_tags, true_preds_tags\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train_and_evaluate(dataset_class, tokenizer, tag2idx, idx2tag, train_tokens, train_tags, max_epochs=10, patience=2, batch_size=16, learning_rate=3e-5):    # Load and prepare data\n",
    "#     tag_values = list(set(tag for doc in train_tags for tag in doc))\n",
    "#     tag_values.append(\"PAD\")\n",
    "#     tag2idx = {tag: idx for idx, tag in enumerate(tag_values)}\n",
    "#     idx2tag = {idx: tag for tag, idx in tag2idx.items()}\n",
    "#     print('len(tag2idx): ', len(tag2idx))\n",
    "#     print('tag_values: ', tag_values)\n",
    "#     # Use the whole training dataset\n",
    "#     train_data = dataset_class(train_tokens, train_tags, tokenizer, MAX_LEN, tag2idx)\n",
    "#     train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "#     # Load the test data\n",
    "#     test_tokens, test_tags = read_data(\"./tagged_sentences_test.iob2\")\n",
    "#     test_data = dataset_class(test_tokens, test_tags, tokenizer, MAX_LEN, tag2idx)\n",
    "#     test_loader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "#     model = BertForTokenClassification.from_pretrained(MODEL_NAME, num_labels=len(tag2idx))\n",
    "#     device = torch.device(\"cpu\")    \n",
    "#     model.to(device)\n",
    "#     optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "#     best_f1 = 0\n",
    "#     patience_counter = 0\n",
    "\n",
    "#     for epoch in range(max_epochs):\n",
    "#         model.train()\n",
    "#         total_loss = 0\n",
    "#         print(f\"Using device: {device}, Epoch {epoch + 1}/{max_epochs}\")\n",
    "\n",
    "#         for step, batch in enumerate(train_loader):\n",
    "#             batch = {k: v.to(device) for k, v in batch.items()}\n",
    "#             outputs = model(**batch)\n",
    "#             loss = outputs.loss\n",
    "#             total_loss += loss.item()\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "#             optimizer.zero_grad()\n",
    "\n",
    "#             if step % 10 == 0:\n",
    "#                 print(f\"Epoch {epoch + 1}, Step {step}, Loss: {loss.item()}\")\n",
    "\n",
    "#         avg_train_loss = total_loss / len(train_loader)\n",
    "#         print(f\"Epoch {epoch + 1}, Average Training Loss: {avg_train_loss}\")\n",
    "\n",
    "#         avg_loss, f1, accuracy, _, _ = evaluate(model, test_loader, device, tag2idx, idx2tag)\n",
    "#         print(f\"Epoch {epoch + 1}, Validation F1: {f1}, Validation Accuracy: {accuracy}\")\n",
    "\n",
    "#         if f1 > best_f1:\n",
    "#             best_f1 = f1\n",
    "#             patience_counter = 0\n",
    "#         else:\n",
    "#             patience_counter += 1\n",
    "\n",
    "#         if patience_counter >= patience:\n",
    "#             print(\"Early stopping triggered\")\n",
    "#             break\n",
    "\n",
    "#     avg_loss, f1, accuracy, true_labels_tags, true_preds_tags = evaluate(model, test_loader, device, tag2idx, idx2tag)\n",
    "#     print(f'Final Average Loss: {avg_loss}')\n",
    "#     print(f'Final F1 Score (excluding PAD and O): {f1}')\n",
    "#     print(f'Final Accuracy (excluding PAD and O): {accuracy}')\n",
    "#     print(classification_report(true_labels_tags, true_preds_tags, target_names=[tag for tag in tag2idx if tag != 'PAD' and tag != 'O']))\n",
    "\n",
    "#     return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Generate learning curve\n",
    "# def generate_learning_curve(dataset_class, tokenizer, tag2idx, idx2tag):\n",
    "#     train_tokens, train_tags = read_data(\"./tagged_sentences_train.iob2\")\n",
    "#     sizes = [0.1, 0.25, 0.5, 0.75, 1.0]\n",
    "#     losses = []\n",
    "#     for size in sizes:\n",
    "#         print('size: ', size)\n",
    "#         # Use only a portion of the data\n",
    "        \n",
    "#         subset_size = int(size * len(train_tokens))\n",
    "#         loss = train_and_evaluate(dataset_class, tokenizer, tag2idx, idx2tag, train_tokens[:subset_size], train_tags[:subset_size])\n",
    "#         losses.append(loss)\n",
    "#     plt.figure(figsize=(10, 6))\n",
    "#     plt.plot([size*100 for size in sizes], losses, marker='o')\n",
    "#     plt.title('Learning Curve')\n",
    "#     plt.xlabel('Training Data Size (%)')\n",
    "#     plt.ylabel('Average Loss')\n",
    "#     plt.grid(True)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate_learning_curve(NERDataset, tokenizer, tag2idx, idx2tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class NERDataset(Dataset):\n",
    "#     def __init__(self, sentences, tags, tokenizer, max_len, tag2idx):\n",
    "#         self.sentences = sentences\n",
    "#         self.tags = tags\n",
    "#         self.tokenizer = tokenizer\n",
    "#         self.max_len = max_len\n",
    "#         self.tag2idx = tag2idx\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.sentences)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         sentence = self.sentences[idx]\n",
    "#         word_labels = self.tags[idx]\n",
    "\n",
    "#         # Tokenize the sentence\n",
    "#         encoding = self.tokenizer(\n",
    "#             sentence,\n",
    "#             is_split_into_words=True,\n",
    "#             return_offsets_mapping=True,\n",
    "#             padding='max_length',\n",
    "#             truncation=True,\n",
    "#             max_length=self.max_len,\n",
    "#             return_tensors='pt'\n",
    "#         )\n",
    "\n",
    "#         # Get the offsets\n",
    "#         offsets = encoding['offset_mapping'].squeeze().tolist()\n",
    "#         encoding.pop('offset_mapping')  # Remove offsets, not needed for model input\n",
    "\n",
    "#         # Initialize labels with \"O\"\n",
    "#         labels = [self.tag2idx['O']] * self.max_len\n",
    "\n",
    "#         idx = 0\n",
    "#         for i, (start, end) in enumerate(offsets):\n",
    "#             if start == end:\n",
    "#                 # Special tokens (CLS, SEP, PAD)\n",
    "#                 labels[i] = self.tag2idx['O']\n",
    "#             elif start == 0:\n",
    "#                 # Start of a new word\n",
    "#                 if idx < len(word_labels):\n",
    "#                     labels[i] = self.tag2idx[word_labels[idx]]\n",
    "#                 idx += 1\n",
    "#             else:\n",
    "#                 # Subtoken of a word\n",
    "#                 labels[i] = -100  # PyTorch's convention to ignore these tokens in loss computation\n",
    "\n",
    "#         item = {key: val.squeeze() for key, val in encoding.items()}  # Remove batch dimension\n",
    "#         item['labels'] = torch.tensor(labels)\n",
    "#         return item\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (bert-try)",
   "language": "python",
   "name": "bert-try"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
